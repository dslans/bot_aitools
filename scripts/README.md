# Setup Scripts

## ğŸš€ Quick Start

Run the comprehensive setup script to initialize the complete database:

```bash
python scripts/setup.py
```

This single script handles everything:

## âœ… What the Setup Script Does

### 1. **Dataset Creation**
- Creates BigQuery dataset (e.g., `aitools_wiki`)
- Sets appropriate location and description
- Handles existing datasets gracefully

### 2. **Core Tables** 
- **`entries`** - Tool submissions with complete schema including `target_audience`
- **`votes`** - User voting records for Reddit-style scoring

### 3. **Community Tag System**
- **`tag_suggestions`** - Community tag proposals with voting metadata
- **`tag_votes`** - Individual votes on tag suggestions  
- **`approved_community_tags`** - Community-approved tags for use

### 4. **Schema Migrations**
- Automatically adds missing columns to existing tables
- Handles incremental schema updates
- Preserves existing data

### 5. **Verification**
- Confirms all tables were created successfully
- Shows table statistics (columns, row counts)
- Reports any issues found

## ğŸ”§ Smart Features

- **Idempotent**: Safe to run multiple times
- **Migration-aware**: Adds missing columns to existing tables  
- **Error handling**: Clear error messages and troubleshooting
- **Verification**: Built-in verification of setup completion

## ğŸ“‹ Prerequisites

1. **Google Cloud Project** set up with BigQuery API enabled
2. **Authentication** configured (service account or `gcloud auth`)
3. **Environment variables** in `.env` file:
   ```
   GOOGLE_CLOUD_PROJECT=your-project-id
   BIGQUERY_DATASET=aitools_wiki
   BIGQUERY_LOCATION=US
   ```

## ğŸ¯ Output Example

```
============================================================
ğŸ¤– AI Tools Wiki Bot - Complete Database Setup
============================================================
ğŸš€ Setting up AI Tools Wiki Bot database...
ğŸ“Š Project: my-project-123
ğŸ“Š Dataset: aitools_wiki
ğŸŒ Location: US

âœ… Dataset my-project-123.aitools_wiki already exists

ğŸ“‹ Setting up core tables...
âœ… Table entries already exists
ğŸ”§ Adding 1 missing columns to entries:
   + target_audience (STRING)
âœ… Updated schema for entries
âœ… Table votes already exists

ğŸ·ï¸ Setting up community tag system...
ğŸ”¨ Creating table: tag_suggestions
âœ… Created table: tag_suggestions
ğŸ”¨ Creating table: tag_votes
âœ… Created table: tag_votes
ğŸ”¨ Creating table: approved_community_tags
âœ… Created table: approved_community_tags

ğŸ‰ Complete database setup finished!
âœ… Dataset created
âœ… Core tables: entries, votes
âœ… Community tag system: tag_suggestions, tag_votes, approved_community_tags
âœ… All schema migrations applied

ğŸ” Verifying setup...
âœ… entries: 9 columns, 0 rows
âœ… votes: 4 columns, 0 rows
âœ… tag_suggestions: 10 columns, 0 rows
âœ… tag_votes: 4 columns, 0 rows
âœ… approved_community_tags: 5 columns, 0 rows

ğŸ‰ All tables verified successfully!

============================================================
ğŸš€ Setup Complete! You can now run: python app.py
============================================================
```

## ğŸ”„ Migration from Old Scripts

If you previously used the individual setup scripts:
- `setup_database.py` âŒ (replaced)
- `add_tag_suggestions_table.py` âŒ (replaced) 
- `migrate_add_target_audience.py` âŒ (replaced)

The new `setup.py` script handles all of these functions automatically and includes additional improvements like verification and better error handling.

## ğŸ†˜ Troubleshooting

### Authentication Issues
```bash
# Set up application default credentials
gcloud auth application-default login

# Or use service account key
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account-key.json"
```

### Permission Issues
Ensure your Google Cloud account has:
- BigQuery Data Editor
- BigQuery Job User  
- BigQuery Admin (for dataset creation)

### Environment Variables
Make sure your `.env` file contains:
```
GOOGLE_CLOUD_PROJECT=your-actual-project-id
BIGQUERY_DATASET=aitools_wiki
```

## ğŸ“ Need Help?

If you encounter issues:
1. Check the error messages - they're designed to be helpful
2. Verify your Google Cloud project and permissions
3. Ensure BigQuery API is enabled in your project
4. Run the script again - it's safe and will show what's already done
